services:
  app:
    container_name: trireme_backend
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - ./env/.env.docker  
    volumes:
      - ./frontend/dist:/frontend/dist
    # networks:
    #   - ollama_network

  frontend:
    container_name: trireme_frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "4200:80"  # Map Angular app to port 4200
    depends_on:
      - app  # Ensure the backend is up before the frontend

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: lklq
      POSTGRES_PASSWORD: "88888888"
      POSTGRES_DB: trireme_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # networks:
    #   - ollama_network

  # ollama:
  #   image: ollama/ollama
  #   container_name: ollama
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=all
  #     - OLLAMA_LLM_LIBRARY=cuda
  #     - OLLAMA_HOST=http://0.0.0.0:11434
  #     - OLLAMA_GPU_OVERHEAD=0
  #     - MODEL=mistral
  #   entrypoint: ["/root/entrypoint.sh"]
  #   ports:
  #     - "11435:11434"  # Change host port to avoid conflicts
  #   volumes:
  #     - ollama:/root/.ollama
  #     - ./entrypoint.sh:/root/entrypoint.sh  # Mount entrypoint script
  #   networks:
  #     - ollama_network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
    
  # codestral:
  #   image: ollama/ollama
  #   container_name: codestral
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=all
  #     - CODESTRAL_LLM_LIBRARY=cuda  # Update as necessary
  #     - CODESTRAL_HOST=http://0.0.0.0:11534
  #     - MODEL=codestral
  #   entrypoint: ["/root/entrypoint.sh"]
  #   ports:
  #     - "11535:11534"  # Assign a unique port for Codestral
  #   volumes:
  #     - codestral:/root/.codestral
  #     - ./entrypoint.sh:/root/entrypoint.sh  # Mount entrypoint script
  #   networks:
  #     - ollama_network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

# networks:
#   ollama_network:
#     external: true

volumes:
  # ollama:
  #   driver: local
  postgres_data:
    driver: local
  # codestral: 
  #   driver: local
