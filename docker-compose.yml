services:
  app:
    container_name: trireme_app
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    networks:
      - ollama_network

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: lklq
      POSTGRES_PASSWORD: "88888888"
      POSTGRES_DB: trireme_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ollama_network

  ollama:
    image: ollama/ollama
    container_name: ollama
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_LLM_LIBRARY=cuda
      - OLLAMA_HOST=http://0.0.0.0:11434
      - OLLAMA_GPU_OVERHEAD=0
    entrypoint: ["/root/entrypoint.sh"]
    ports:
      - "11435:11434"  # Change host port to avoid conflicts
    volumes:
      - ollama:/root/.ollama
      - ./entrypoint.sh:/root/entrypoint.sh  # Mount entrypoint script
    networks:
      - ollama_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  ollama_network:
    external: true

volumes:
  ollama:
    driver: local
  postgres_data:
    driver: local
